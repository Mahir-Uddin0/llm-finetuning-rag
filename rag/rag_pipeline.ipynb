{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13466316,"sourceType":"datasetVersion","datasetId":8548198},{"sourceId":621070,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":467088,"modelId":482912}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q langchain faiss-cpu unstructured PyPDF2\n!pip install -q huggingface_hub\n!pip install -U langchain-community langchain-huggingface\n!pip install -q langchain-huggingface\n!pip install transformers datasets tqdm ddgs\n!pip install langchain-embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:12:52.443273Z","iopub.execute_input":"2025-10-27T21:12:52.443579Z","iopub.status.idle":"2025-10-27T21:13:22.491741Z","shell.execute_reply.started":"2025-10-27T21:12:52.443555Z","shell.execute_reply":"2025-10-27T21:13:22.490507Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.8/449.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\nlangchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.3.11 which is incompatible.\nlangchain-huggingface 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.3.79 which is incompatible.\nlangchain-community 0.4.1 requires langchain-core<2.0.0,>=1.0.1, but you have langchain-core 0.3.79 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.4.1)\nRequirement already satisfied: langchain-huggingface in /usr/local/lib/python3.11/dist-packages (1.0.0)\nCollecting langchain-core<2.0.0,>=1.0.1 (from langchain-community)\n  Using cached langchain_core-1.0.1-py3-none-any.whl.metadata (3.5 kB)\nRequirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.0.0)\nRequirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\nRequirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.5)\nRequirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.3)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.11.0)\nRequirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.33.4 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.36.0)\nRequirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (3.19.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (2025.9.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (25.0)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain-huggingface) (1.1.10)\nCollecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n  Using cached langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.0a1)\nRequirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.0)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.8.3)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.11.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.37.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.37.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain-community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain-community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.3.1)\nUsing cached langchain_core-1.0.1-py3-none-any.whl (467 kB)\nUsing cached langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\nInstalling collected packages: langchain-core, langchain-text-splitters\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.79\n    Uninstalling langchain-core-0.3.79:\n      Successfully uninstalled langchain-core-0.3.79\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.11\n    Uninstalling langchain-text-splitters-0.3.11:\n      Successfully uninstalled langchain-text-splitters-0.3.11\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 1.0.1 which is incompatible.\nlangchain 0.3.27 requires langchain-text-splitters<1.0.0,>=0.3.9, but you have langchain-text-splitters 1.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-core-1.0.1 langchain-text-splitters-1.0.0\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.1.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: ddgs in /usr/local/lib/python3.11/dist-packages (9.6.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.19.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: pyarrow>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (22.0.0)\nRequirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.4.0)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\nRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from ddgs) (8.3.0)\nRequirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (0.15.0)\nRequirement already satisfied: lxml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from ddgs) (6.0.2)\nRequirement already satisfied: httpx>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.28.1)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.11.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (2025.8.3)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (0.16.0)\nRequirement already satisfied: brotli in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.1.0)\nRequirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.3.0)\nRequirement already satisfied: socksio==1.* in /usr/local/lib/python3.11/dist-packages (from httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.10)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\nRequirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (6.1.0)\nRequirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[brotli,http2,socks]>=0.28.1->ddgs) (4.1.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.28.1->httpx[brotli,http2,socks]>=0.28.1->ddgs) (1.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-embedding (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for langchain-embedding\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import os\nimport json\nfrom tqdm import tqdm\nfrom langchain.vectorstores import FAISS\nfrom langchain.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:30:32.034879Z","iopub.execute_input":"2025-10-27T19:30:32.035678Z","iopub.status.idle":"2025-10-27T19:31:19.463534Z","shell.execute_reply.started":"2025-10-27T19:30:32.035655Z","shell.execute_reply":"2025-10-27T19:31:19.462830Z"}},"outputs":[{"name":"stderr","text":"2025-10-27 19:30:55.592773: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761593455.916774      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761593456.006644      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# PDF Embedding","metadata":{}},{"cell_type":"code","source":"pdf_folder = \"/kaggle/input/investing-books-pdf\"  # change path if needed\npdf_files = [os.path.join(pdf_folder, f) for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:31:19.464185Z","iopub.execute_input":"2025-10-27T19:31:19.464751Z","iopub.status.idle":"2025-10-27T19:31:19.589735Z","shell.execute_reply.started":"2025-10-27T19:31:19.464736Z","shell.execute_reply":"2025-10-27T19:31:19.588728Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"all_documents = []\n\nfor pdf_path in pdf_files:\n    loader = PyPDFLoader(pdf_path)\n    docs = loader.load()  # this returns list of Document objects\n    all_documents.extend(docs)\n\nprint(f\"Loaded {len(all_documents)} documents from PDFs.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:31:19.591789Z","iopub.execute_input":"2025-10-27T19:31:19.592976Z","iopub.status.idle":"2025-10-27T19:33:06.836771Z","shell.execute_reply.started":"2025-10-27T19:31:19.592931Z","shell.execute_reply":"2025-10-27T19:33:06.835511Z"}},"outputs":[{"name":"stdout","text":"Loaded 4382 documents from PDFs.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.schema import Document\nfrom typing import List\n\ndef split_text(documents):\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=2000,\n        chunk_overlap=350\n    )\n    split_docs = text_splitter.split_documents(documents)\n    print(f\"Created {len(split_docs)} text chunks.\")\n    return split_docs\n\n\n# Example documents\ndocs = [\n    Document(page_content=\"This is the content of document 1.\"),\n    Document(page_content=\"This is the content of document 2.\")\n]\n\nchunks = split_text(docs)\nprint(chunks[0].page_content)  # first chunk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T20:52:50.452576Z","iopub.execute_input":"2025-10-27T20:52:50.454211Z","iopub.status.idle":"2025-10-27T20:52:51.267773Z","shell.execute_reply.started":"2025-10-27T20:52:50.454155Z","shell.execute_reply":"2025-10-27T20:52:51.266751Z"}},"outputs":[{"name":"stdout","text":"Created 2 text chunks.\nThis is the content of document 1.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# 3) Split text into chunks\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=2000,   \n    chunk_overlap=350  \n)\n\nsplit_docs = text_splitter.split_documents(all_documents)\nprint(f\"Created {len(split_docs)} text chunks.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:33:06.846653Z","iopub.execute_input":"2025-10-27T19:33:06.846873Z","iopub.status.idle":"2025-10-27T19:33:08.252803Z","shell.execute_reply.started":"2025-10-27T19:33:06.846854Z","shell.execute_reply":"2025-10-27T19:33:08.251720Z"}},"outputs":[{"name":"stdout","text":"Created 8126 text chunks.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"split_docs[159].page_content","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:33:08.254178Z","iopub.execute_input":"2025-10-27T19:33:08.254541Z","iopub.status.idle":"2025-10-27T19:33:08.262057Z","shell.execute_reply.started":"2025-10-27T19:33:08.254510Z","shell.execute_reply":"2025-10-27T19:33:08.260635Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'John\\'s z-score of –0.21 is higher than Ali\\'s z-score of –0.3. For GPA, higher values are better, so we conclude that John has\\nthe better GPA when compared to his school.\\nTRY IT 2.32\\nTwo swimmers, Angie and Beth, from different teams, wanted to find out who had the fastest time for the 50 meter\\nfreestyle when compared to her team. Which swimmer had the fastest time when compared to her team?\\nSwimmer Time (seconds) Team mean time Team standard deviation\\nAngie 26.2 27.2 0.8\\nBeth 27.3 30.1 1.4\\nTable2.36\\nThe following lists give a few facts that provide a little more insight into what the standard deviation tells us about the\\ndistribution of the data.\\nFor ANY data set, no matter what the distribution of the data is:\\n• At least 75% of the data is within two standard deviations of the mean.\\n• At least 89% of the data is within three standard deviations of the mean.\\n• At least 95% of the data is within 4.5 standard deviations of the mean.\\n• This is known as Chebyshev\\'s Rule.\\nFor data having a Normal Distribution, which we will examine in great detail later:\\n• Approximately 68% of the data is within one standard deviation of the mean.\\n• Approximately 95% of the data is within two standard deviations of the mean.\\n• More than 99% of the data is within three standard deviations of the mean.\\n• This is known as the Empirical Rule.\\n• It is important to note that this rule only applies when the shape of the distribution of the data is bell-shaped and\\nsymmetric. We will learn more about this when studying the \"Normal\" or \"Gaussian\" probability distribution in later\\nchapters.\\nCoefficient of Variation\\nAnother useful way to compare distributions besides simple comparisons of means or standard deviations is to adjust\\nfor differences in the scale of the data being measured. Quite simply, a large variation in data with a large mean is\\ndifferent than the same variation in data with a small mean. To adjust for the scale of the underlying data the Coefficient'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"!pip install InstructorEmbedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T20:34:24.894210Z","iopub.execute_input":"2025-10-27T20:34:24.895057Z","iopub.status.idle":"2025-10-27T20:34:30.878497Z","shell.execute_reply.started":"2025-10-27T20:34:24.895027Z","shell.execute_reply":"2025-10-27T20:34:30.877144Z"}},"outputs":[{"name":"stdout","text":"Collecting InstructorEmbedding\n  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\nDownloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: InstructorEmbedding\nSuccessfully installed InstructorEmbedding-1.0.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from InstructorEmbedding import INSTRUCTOR\nimport os\n\ndef get_embeddings(texts, model_path=\"/kaggle/input/qwen-3-embedding/transformers/4b/1\", batch_size=8):\n    # Path to your local embedding model\n    model_path = \"/kaggle/input/qwen-3-embedding/transformers/4b/1\"\n    \n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Using device: {device}\")\n    \n    # Load the local embedding model\n    embeddings = INSTRUCTOR(model_path, device=device)\n\n    vector_list = embeddings_model.encode(texts, batch_size=batch_size)\n    \n    return vector_list\n\n# Example usage:\ntexts = [\"This is a sample text.\", \"Another example sentence.\"]\nvectors = get_embeddings(texts)\nprint(vectors[0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T20:34:38.740070Z","iopub.execute_input":"2025-10-27T20:34:38.740959Z","iopub.status.idle":"2025-10-27T20:36:39.339400Z","shell.execute_reply.started":"2025-10-27T20:34:38.740922Z","shell.execute_reply":"2025-10-27T20:36:39.338249Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import trange\n2025-10-27 20:34:58.739123: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761597299.042802      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761597299.126265      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c0052aedee845508df5f230d5dca1ea"}},"metadata":{}},{"name":"stdout","text":"(2560,)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"vector_list","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T20:37:34.750563Z","iopub.execute_input":"2025-10-27T20:37:34.750920Z","iopub.status.idle":"2025-10-27T20:37:34.758106Z","shell.execute_reply.started":"2025-10-27T20:37:34.750894Z","shell.execute_reply":"2025-10-27T20:37:34.756853Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"array([[-0.02290262,  2.7810962 ,  4.3660984 , ..., -1.4585104 ,\n        -1.3493048 ,  1.0481972 ],\n       [-0.02347616,  2.7970245 ,  4.2245073 , ...,  0.99478084,\n        -2.4863873 ,  2.1848664 ]], dtype=float32)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# 5) Build FAISS vector store\n# -------------------------------\nvector_db = FAISS.from_documents(split_docs, embeddings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:33:08.661331Z","iopub.status.idle":"2025-10-27T19:33:08.661677Z","shell.execute_reply.started":"2025-10-27T19:33:08.661519Z","shell.execute_reply":"2025-10-27T19:33:08.661534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Web Search","metadata":{}},{"cell_type":"code","source":"from ddgs import DDGS\nfrom langchain.schema import Document\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef web_search(query, max_results=3):\n    docs = []\n\n    # Search the web using DuckDuckGo\n    with DDGS() as ddgs:\n        results = list(ddgs.text(query, max_results=max_results))\n\n    for result in results:\n        url = result.get(\"href\")\n        title = result.get(\"title\")\n\n        try:\n            # Fetch the web page content\n            response = requests.get(url, timeout=10)\n            response.raise_for_status()\n\n            # Parse visible text from HTML\n            soup = BeautifulSoup(response.text, \"html.parser\")\n            for tag in soup([\"script\", \"style\", \"noscript\"]):\n                tag.extract()\n            text = \" \".join(soup.get_text(separator=\" \").split())\n\n            # Only keep if text length is reasonable\n            if len(text) > 500:\n                docs.append(Document(page_content=text, metadata={\"source\": url, \"title\": title}))\n        except Exception as e:\n            # print(f\"⚠️ Skipping {url}: {e}\")\n\n    # print(f\"✅ Retrieved {len(docs)} web documents from top {max_results} results.\")\n    return docs\n\nquery = \"Tesla 2025 annual revenue analysis\"\ndocuments = web_search(query)\n\nprint(f\"Number of documents: {len(documents)}\")\nprint(documents[0].metadata)\nprint(documents[0].page_content[:500])  # preview text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T21:14:06.963444Z","iopub.execute_input":"2025-10-27T21:14:06.966427Z","iopub.status.idle":"2025-10-27T21:14:15.986004Z","shell.execute_reply.started":"2025-10-27T21:14:06.966355Z","shell.execute_reply":"2025-10-27T21:14:15.984458Z"}},"outputs":[{"name":"stdout","text":"✅ Retrieved 3 web documents from top 3 results.\nNumber of documents: 3\n{'source': 'https://stockanalysis.com/stocks/tsla/revenue/', 'title': 'Tesla (TSLA) Revenue 2015-2025'}\nTesla (TSLA) Revenue 2015-2025 Skip to main content Log In Sign Up Home Watchlist Stocks Stock Screener Stock Exchanges Comparison Tool Earnings Calendar By Industry Stock Lists Top Analysts Top Stocks Corporate Actions IPOs Recent IPOs IPO Calendar IPO Statistics IPO News IPO Screener ETFs ETF Screener Comparison Tool New Launches ETF Providers News Trending Articles Technical Chart Market Movers Top Gainers Top Losers Most Active Premarket After Hours Market Heatmap Market Newsletter Stock Ana\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Web PDF Retriever","metadata":{}},{"cell_type":"code","source":"from ddgs import DDGS\n\ndef search_pdfs(company_name, year=2024, max_results=5):\n    query = f\"{company_name} {year} annual report filetype:pdf\"\n    with DDGS() as ddgs:\n        results = list(ddgs.text(query, max_results=max_results))\n    pdf_links = [r['href'] for r in results if r['href'].endswith('.pdf')]\n    return pdf_links\n\n# Example:\npdf_urls = search_pdfs(\"Square Pharma\", 2024)\nprint(pdf_urls)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:33:08.667088Z","iopub.status.idle":"2025-10-27T19:33:08.667681Z","shell.execute_reply.started":"2025-10-27T19:33:08.667432Z","shell.execute_reply":"2025-10-27T19:33:08.667453Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import requests\n\ndef download_pdf(url, save_path):\n    response = requests.get(url, stream=True)\n    if response.status_code == 200 and 'application/pdf' in response.headers.get('Content-Type', ''):\n        with open(save_path, 'wb') as f:\n            for chunk in response.iter_content(1024):\n                f.write(chunk)\n        print(f\"✅ Downloaded: {save_path}\")\n    else:\n        print(\"❌ Not a valid PDF or download failed.\")\n# if pdf_urls:\n    # for i in range(len(pdf_urls)):\n        # download_pdf(pdf_urls[4], \"apple_2024_annual_report.pdf\")\ndownload_pdf(\"https://www.squarepharma.com.bd/downloads/Square%20Pharma_AR_24%20dt-24-11-24_compressed_1.pdf\", \"hjd.pdf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-27T19:33:08.670099Z","iopub.status.idle":"2025-10-27T19:33:08.670506Z","shell.execute_reply.started":"2025-10-27T19:33:08.670325Z","shell.execute_reply":"2025-10-27T19:33:08.670343Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Chain Construction","metadata":{}},{"cell_type":"code","source":"from langchain.schema import Document\nfrom langchain.runnables import (\n    RunnablePassthrough,\n    RunnableLambda,\n    RunnableSequence,\n    RunnableParallel,\n)\n\n# 1️⃣ User query passthrough\nuser_input = RunnablePassthrough()  # receives query from user\n\n# 2️⃣ Online text search branch\nonline_text_chain = RunnableSequence(\n    [\n        RunnableLambda(lambda query: web_search(query)),  # returns raw text from web\n        RunnableLambda(lambda text: split_text(text)),            # split into chunks\n        RunnableLambda(lambda chunks: get_embeddings(chunks)),       # embeddings\n    ]\n)\n\n# 3️⃣ Online PDF retrieval branch\nonline_pdf_chain = RunnableSequence(\n    [\n        RunnableLambda(lambda query: get_pdf_links(query)),       # get online PDF URLs\n        RunnableLambda(lambda urls: download_pdfs(urls)),        # download PDFs\n        RunnableLambda(lambda pdf_texts: split_text(pdf_texts)), # split text\n        RunnableLambda(lambda chunks: get_embeddings(chunks)),       # embeddings\n    ]\n)\n\n# 4️⃣ Preloaded investing book PDFs branch\nbook_pdf_chain = RunnableSequence(\n    [\n        RunnablePassthrough(),                 # preloaded PDF Documents passed in\n        RunnableLambda(lambda docs: split_text(docs)),  # split into chunks\n        RunnableLambda(lambda chunks: get_embeddings(chunks)),  # embeddings\n    ]\n)\n\n# 5️⃣ Parallel execution of the three branches\nparallel_chain = RunnableParallel(\n    {\n        \"books\": book_pdf_chain,\n        \"online_text\": online_text_chain,\n        \"online_pdf\": online_pdf_chain\n    },\n    combine_mode=\"list\",  # returns a list of embeddings for each branch\n)\n\n# 6️⃣ Combine embeddings and build retrieval chain\ncombine_chain = RunnableSequence(\n    [\n        RunnableLambda(lambda embedding_lists: combine_embeddings(embedding_lists)),  # merge all embeddings\n        RunnableLambda(lambda vector_db: rag_retrieval(vector_db)),                   # retrieval + augmentation\n        RunnableLambda(lambda result: generate_answer(result)),                        # LLM generation\n    ]\n)\n\n# 7️⃣ Full pipeline: sequence of parallel + combine\nfull_pipeline = RunnableSequence([parallel_chain, combine_chain])\n\n# Example usage:\n# preloaded_books = [...]  # list of Document objects\n# query = \"Analyze Tesla 2024 competition and market behavior\"\n# output = full_pipeline.invoke([preloaded_books, query, query])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}